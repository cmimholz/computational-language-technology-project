{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Enhanced Data Cleaning, Preprocessing, and Exploratory Analysis \n",
    "In this notebook, we perform **data cleaning, preprocessing, and exploratory analysis (EDA)** on the Cleantech Media and Google Patent datasets. The goal is to identify **trends, key technologies, and innovation gaps** by analyzing media publications and patents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and Cleaning\n",
    "Before analyzing the data, we first **load, inspect, and clean** the datasets:  \n",
    "\n",
    "- **Load datasets**: We import the **Cleantech Media Dataset** and the **Cleantech Google Patent Dataset** into Pandas DataFrames.  \n",
    "- **Remove duplicates**: Identical or near-identical entries are removed to prevent data bias.  \n",
    "- **Handle missing values**: We check for null or incomplete entries and decide whether to impute, replace, or remove them.  \n",
    "- **Filter relevant information**: Non-informative texts (e.g., generic statements) are removed to ensure high-quality analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw cleantech_media_dataset_v3_2024-10-28.csv:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20111 entries, 0 to 20110\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  20111 non-null  int64  \n",
      " 1   title       20111 non-null  object \n",
      " 2   date        20111 non-null  object \n",
      " 3   author      0 non-null      float64\n",
      " 4   content     20111 non-null  object \n",
      " 5   domain      20111 non-null  object \n",
      " 6   url         20111 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "Raw cleantech_rag_evaluation_data_2024-09-20.csv:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23 entries, 0 to 22\n",
      "Data columns (total 6 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   example_id                  23 non-null     object\n",
      " 1   question_id                 23 non-null     object\n",
      " 2   question                    23 non-null     object\n",
      " 3   relevant_text               22 non-null     object\n",
      " 4   answer                      22 non-null     object\n",
      " 5   article_url,,,,,,,,,,,,,,,  22 non-null     object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.2+ KB\n",
      "None\n",
      "  example_id question_id             question        relevant_text  \\\n",
      "0          1           1  What is the inno...  Leclanché said i...   \n",
      "1          2           2  What is the EU’s...  The Green Deal I...   \n",
      "2          3           2  What is the EU’s...  The European cou...   \n",
      "3          4           3  What are the fou...  The new plan is ...   \n",
      "4          5           4  When did the coo...  What caught our ...   \n",
      "\n",
      "                answer article_url,,,,,,,,,,,,,,,  \n",
      "0  Leclanché's inno...  https://www.sgvo...        \n",
      "1  The EU’s Green D...  https://www.sgvo...        \n",
      "2  The EU’s Green D...  https://www.pv-m...        \n",
      "3  The four focus a...  https://www.sgvo...        \n",
      "4            July 2013  https://cleantec...        \n"
     ]
    }
   ],
   "source": [
    "media_dataset_path = \"../data/cleantech_media_dataset_v3_2024-10-28.csv\"\n",
    "google_patent_dataset_path = \"../data/cleantech_rag_evaluation_data_2024-09-20.csv\"\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 20)\n",
    "\n",
    "# Load CSV files\n",
    "df_media = pd.read_csv(media_dataset_path, header = 0)\n",
    "df_google_patents = pd.read_csv(google_patent_dataset_path, sep = \";\", header = 0)\n",
    "\n",
    "print(\"Raw cleantech_media_dataset_v3_2024-10-28.csv:\")\n",
    "print(df_media.info())\n",
    "df_media\n",
    "\n",
    "print(\"Raw cleantech_rag_evaluation_data_2024-09-20.csv:\")\n",
    "print(df_google_patents.info())\n",
    "print(df_google_patents.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93320</td>\n",
       "      <td>XPeng Delivered ...</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>['Chinese automo...</td>\n",
       "      <td>cleantechnica</td>\n",
       "      <td>https://cleantec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93321</td>\n",
       "      <td>Green Hydrogen: ...</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>['Sinopec has la...</td>\n",
       "      <td>cleantechnica</td>\n",
       "      <td>https://cleantec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98159</td>\n",
       "      <td>World’ s largest...</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>['Huaneng Power ...</td>\n",
       "      <td>pv-magazine</td>\n",
       "      <td>https://www.pv-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98158</td>\n",
       "      <td>Iran wants to de...</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>['According to t...</td>\n",
       "      <td>pv-magazine</td>\n",
       "      <td>https://www.pv-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31128</td>\n",
       "      <td>Eastern Intercon...</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>['Sign in to get...</td>\n",
       "      <td>naturalgasintel</td>\n",
       "      <td>https://www.natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20106</th>\n",
       "      <td>104263</td>\n",
       "      <td>US Treasury fina...</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>['The US Departm...</td>\n",
       "      <td>pv-tech</td>\n",
       "      <td>https://www.pv-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20107</th>\n",
       "      <td>104264</td>\n",
       "      <td>EDP trials robot...</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>['Developer EDP ...</td>\n",
       "      <td>pv-tech</td>\n",
       "      <td>https://www.pv-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20108</th>\n",
       "      <td>101434</td>\n",
       "      <td>Australia has 7....</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>['The volume of ...</td>\n",
       "      <td>pv-magazine</td>\n",
       "      <td>https://www.pv-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20109</th>\n",
       "      <td>101428</td>\n",
       "      <td>Residential PV p...</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>['The comparison...</td>\n",
       "      <td>pv-magazine</td>\n",
       "      <td>https://www.pv-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20110</th>\n",
       "      <td>101431</td>\n",
       "      <td>KAUST, Helmholtz...</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>['The perovskite...</td>\n",
       "      <td>pv-magazine</td>\n",
       "      <td>https://www.pv-m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20111 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                title        date              content  \\\n",
       "0       93320  XPeng Delivered ...  2022-01-02  ['Chinese automo...   \n",
       "1       93321  Green Hydrogen: ...  2022-01-02  ['Sinopec has la...   \n",
       "2       98159  World’ s largest...  2022-01-03  ['Huaneng Power ...   \n",
       "3       98158  Iran wants to de...  2022-01-03  ['According to t...   \n",
       "4       31128  Eastern Intercon...  2022-01-03  ['Sign in to get...   \n",
       "...       ...                  ...         ...                  ...   \n",
       "20106  104263  US Treasury fina...  2024-10-24  ['The US Departm...   \n",
       "20107  104264  EDP trials robot...  2024-10-24  ['Developer EDP ...   \n",
       "20108  101434  Australia has 7....  2024-10-24  ['The volume of ...   \n",
       "20109  101428  Residential PV p...  2024-10-24  ['The comparison...   \n",
       "20110  101431  KAUST, Helmholtz...  2024-10-24  ['The perovskite...   \n",
       "\n",
       "                domain                  url  \n",
       "0        cleantechnica  https://cleantec...  \n",
       "1        cleantechnica  https://cleantec...  \n",
       "2          pv-magazine  https://www.pv-m...  \n",
       "3          pv-magazine  https://www.pv-m...  \n",
       "4      naturalgasintel  https://www.natu...  \n",
       "...                ...                  ...  \n",
       "20106          pv-tech  https://www.pv-t...  \n",
       "20107          pv-tech  https://www.pv-t...  \n",
       "20108      pv-magazine  https://www.pv-m...  \n",
       "20109      pv-magazine  https://www.pv-m...  \n",
       "20110      pv-magazine  https://www.pv-m...  \n",
       "\n",
       "[20111 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe for the processed data\n",
    "df_media_processed = df_media.rename(columns={df_media.columns[0]: 'id'})\n",
    "df_media_processed.drop(columns=['author'], inplace=True)\n",
    "df_media_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "To ensure that the text data is **ready for NLP tasks**, we preprocess it using common natural language processing (NLP) techniques:  \n",
    "\n",
    "- **Tokenization**: Split text into individual words or subwords for better analysis.  \n",
    "- **Stopword Removal**: Common but uninformative words (e.g., \"the\", \"is\", \"and\") are removed.  \n",
    "- **Stemming & Lemmatization**: Words are reduced to their root form (e.g., \"developing\" → \"develop\").  \n",
    "- **Lowercasing**: Standardize all text to lowercase to avoid duplicate entries.  \n",
    "\n",
    "These steps improve the quality of text-based analysis and ensure consistency across datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "EDA helps us **understand data patterns and distributions** before applying complex NLP models. We perform:  \n",
    "\n",
    "- **Temporal Analysis**: We examine **publication trends** over time to detect emerging Cleantech topics.  \n",
    "- **Named Entity Recognition (NER)**: Identify key **companies, organizations, and technologies** frequently mentioned in the datasets.  \n",
    "- **Word Frequency Analysis**: Find the most common words and phrases across media and patents.  \n",
    "- **Visualization**:  \n",
    "  - **Word Clouds** to showcase frequently occurring terms  \n",
    "  - **Bar Charts** to compare key industry players and technology mentions  \n",
    "  - **Network Graphs** to analyze relationships between companies and technologies  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "To **identify hidden themes and emerging trends**, we apply topic modeling techniques on both datasets:  \n",
    "\n",
    "- **Latent Dirichlet Allocation (LDA)** and **Non-Negative Matrix Factorization (NMF)** to uncover broad thematic structures.  \n",
    "- **Top2Vec** and **BERTopic** for **more dynamic and context-aware topic modeling**.  \n",
    "- **Comparing Media vs. Patents**:  \n",
    "  - Which Cleantech topics are **gaining media attention** but **not patented** yet?  \n",
    "  - Are **patents aligned with market trends**, or do they focus on different areas?  \n",
    "  - **What are the innovation gaps** between research and real-world applications?  \n",
    "\n",
    "By the end of this step, we will have a **structured view of the Cleantech landscape**, highlighting **key trends, players, and technological opportunities**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
